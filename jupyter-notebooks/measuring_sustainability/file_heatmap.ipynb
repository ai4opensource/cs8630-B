{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c171295-95e9-4807-a417-0bcca77fd6b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewer/Contributor Heatmap Discussion Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb5516-a84a-4541-8191-b486fbfaef85",
   "metadata": {},
   "source": [
    "This notebook will be the development ground for an activity heatmap from the perspectives of: \n",
    "- Contributors (Someone who has had a PR merged on the specific segment of the codebase) \n",
    "- Reviewers (Someone who has reviewed a PR on the specific segment of the codebase)\n",
    "\n",
    "The x axis will be a break down of the repository folders and source files. The first iteration will statically show the source directory folders and files. The next iteration will allow users to select a more granular view on specific sections of the codebase. A part of this notebook review will be to get suggestions and feedback on how to impliment this. \n",
    "\n",
    "The initial concept of the visualization is as followed:\n",
    "\n",
    "User selects which specific repository in the repositories in their search bar to show on heat map\n",
    "User specifies a time interval in days that a reviewer needs to show some form of activity in the overall repo set\n",
    "Then one of the following plotly heat maps is used:\n",
    "https://plotly.com/python/heatmaps/\n",
    "https://plotly.com/python/2D-Histogram/\n",
    "\n",
    "- x axis: date by month in descending order\n",
    "- y axis: repository folder (or file, need to workshop this a bit)\n",
    "- z axis (color): Number of reviewers that have been active in the time interval (relative to the month block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bd000-d728-4991-b92f-f727c078575a",
   "metadata": {},
   "source": [
    "This notebook does all of the preprocessing down to the visualization for we can try different strategies before putting it into 8Knot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bae68a-53e5-47b6-93d1-7c93413517da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd \n",
    "import sqlalchemy as salc\n",
    "import json\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "import plotly\n",
    "import math\n",
    "from IPython.display import Image\n",
    "\n",
    "# connect to db\n",
    "import json\n",
    "import os\n",
    "\n",
    "paths = [\"../../comm_cage.json\", \"comm_cage.json\", \"../../config.json\", \"../config.json\", \"config.json\", \"../../copy_cage-padres.json\"]\n",
    "\n",
    "for path in paths:\n",
    "    if os.path.exists(path):\n",
    "        with open(path) as config_file:\n",
    "            config = json.load(config_file)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"None of the config files found: {paths}\")\n",
    "        \n",
    "database_connection_string = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(config['user'], config['password'], config['host'], config['port'], config['database'])\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = salc.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad165b59-9469-497e-811a-852064523b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection_string = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(config['user'], config['password'], config['host'], config['port'], config['database'])\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = salc.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627cb1c-e411-4e4d-8f4b-12d58c6e22f9",
   "metadata": {},
   "source": [
    "Get repo_ids for augur data access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4dafd-4852-471b-af78-53a745d490ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_urls = ['https://github.com/opendatahub-io/data-science-pipelines-operator','https://github.com/pulp/pulp-infra-ansible'\n",
    "             ,'https://github.com/opendatahub-io/data-science-pipelines','https://github.com/chaoss/augur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab93bdc-9526-472b-8c78-f59ec808f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text, bindparam\n",
    "\n",
    "repo_urls = [\n",
    "    'https://github.com/opendatahub-io/data-science-pipelines-operator',\n",
    "    'https://github.com/pulp/pulp-infra-ansible',\n",
    "    'https://github.com/opendatahub-io/data-science-pipelines',\n",
    "    'https://github.com/chaoss/augur'\n",
    "]\n",
    "\n",
    "stmt = text(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        r.repo_id,\n",
    "        r.repo_name\n",
    "    FROM repo r\n",
    "    JOIN repo_groups rg ON r.repo_group_id = rg.repo_group_id\n",
    "    WHERE r.repo_git IN :urls\n",
    "\"\"\").bindparams(bindparam(\"urls\", expanding=True))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    rows = conn.execute(stmt, {\"urls\": repo_urls}).all()\n",
    "\n",
    "repo_ids   = [row[0] for row in rows]\n",
    "repo_names = [row[1] for row in rows]\n",
    "print(repo_ids)\n",
    "print(repo_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e1bb9-e2af-49e1-964b-34a1dcf2e9d1",
   "metadata": {},
   "source": [
    "This visualization is to be done on a single repo but we will use the 4 repo_ids to test out the stategy on difference file structures and contributor density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45866a5b-48ae-4f49-9ed2-b292c957f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf08d12-e033-42d8-ba3e-fffce79b0476",
   "metadata": {},
   "source": [
    "## File query and preprocessing\n",
    "\n",
    "Query to get all the files identified in the repo_labor table for the specific repository. For each collection of repo_labor, every file in current (as of that collection) existance is a row. During the preprocessing steps we will only keep the entries from the most recent collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c59968-f7d0-4f9f-a469-93f7bd3bb828",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_query = salc.sql.text(f\"\"\"\n",
    "                SELECT \n",
    "                    rl.repo_id,\n",
    "                    r.repo_name,\n",
    "                    r.repo_path,\n",
    "                    rl.rl_analysis_date,\n",
    "                    rl.file_path,\n",
    "                    rl.file_name\n",
    "                FROM \n",
    "                    repo_labor rl,\n",
    "                    repo r\n",
    "                WHERE \n",
    "                    rl.repo_id = {repo_id} AND \n",
    "                    rl.repo_id = r.repo_id\n",
    "                \"\"\")\n",
    "df_file = pd.read_sql(file_query, con=engine)\n",
    "\n",
    "df_file = df_file.reset_index()\n",
    "df_file.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a99c7-33ad-4caa-8d8a-43914f7cccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cd50e-c4da-4659-b73d-4133f4122528",
   "metadata": {},
   "source": [
    "The file path directly from the query has a lot of excess text that is not useful to us. The following 3 cells will be to slice the excess characters to only leave the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8250d01-9970-43ce-b178-5f2343cd83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings to hold the values for each column (always the same for every row of this query)\n",
    "repo_name = df_file[\"repo_name\"].iloc[0]\n",
    "repo_path = df_file[\"repo_path\"].iloc[0]\n",
    "repo_id = str(df_file[\"repo_id\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c27b8b-642d-4fc3-9e7d-91990e05eb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pattern found in each file path, used to slice to get only the root file path \n",
    "path_slice = repo_id + '-' + repo_path +  '/' + repo_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852277a7-8103-46f9-958b-d59f2f98e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file[\"file_path\"] = df_file[\"file_path\"].str.rsplit(path_slice,n= 1).str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8c93c-c945-4f40-beea-c2d8421358e4",
   "metadata": {},
   "source": [
    "Drop all of the columns not in the most recent collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66827202-2734-4da5-abf4-4daba5efb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = df_file[df_file[\"rl_analysis_date\"] == df_file[\"rl_analysis_date\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4652e5-947b-4201-aa6b-3b30d816065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccessary columns not needed after preprocessing steps\n",
    "df_file = df_file.reset_index()\n",
    "df_file.drop([\"index\",\"repo_id\",\"repo_name\",\"repo_path\",\"rl_analysis_date\" ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20fded-263e-4002-a9db-1751e82a5d39",
   "metadata": {},
   "source": [
    "Results in the most current set of files and their path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275672f-7086-442b-9729-25c8b80fffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3222b7-9d7e-442a-9e4c-ca7a4f7dfdb3",
   "metadata": {},
   "source": [
    "## Contributor information preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd881d7f-62fc-42cf-8790-085d35ca3cd8",
   "metadata": {},
   "source": [
    "### Contributors per file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68373f2-4120-40b5-8d46-333f38d4f8c6",
   "metadata": {},
   "source": [
    "Query to get all of the contributors that have opened a pr that included each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f0cfb-8b5d-46a1-af9d-1970bc83f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrb_query = salc.sql.text(f\"\"\"\n",
    "                SELECT \n",
    "                    prf.pr_file_path as file_path, \n",
    "                    string_agg(DISTINCT CAST(pr.pr_augur_contributor_id AS varchar(20)), ',') AS cntrb_ids\n",
    "                FROM\n",
    "                    pull_requests pr, \n",
    "                    pull_request_files prf\n",
    "                WHERE \n",
    "                    pr.pull_request_id = prf.pull_request_id AND \n",
    "                    pr.repo_id = {repo_id}\n",
    "                GROUP BY prf.pr_file_path \n",
    "                \"\"\")\n",
    "df_cntrb = pd.read_sql(cntrb_query, con=engine)\n",
    "\n",
    "df_cntrb[\"cntrb_ids\"] = df_cntrb[\"cntrb_ids\"].str.split(\",\")\n",
    "df_cntrb = df_cntrb.reset_index()\n",
    "df_cntrb.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091fd19-6d32-453d-bb82-a76ede5e3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cntrb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167bba7-f58d-42aa-910e-1b12c3bf7bc9",
   "metadata": {},
   "source": [
    "Query to get all of the contributors that have reviewed a pr that included each file - *will fill in when augur bug fix is in*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f615970-a317-4244-86d4-6419e38564b6",
   "metadata": {},
   "source": [
    "#### Combine df_files and contributor information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28685c-1848-4570-89f1-dfdfca4db86c",
   "metadata": {},
   "source": [
    "Left join on df_files to only get the files that are currently in the repository and the contributors that have ever opened a pr that included edits on the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923721c-8145-42bd-9d70-0e018d25dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = pd.merge(df_file,df_cntrb, on = 'file_path', how = 'left' )\n",
    "# replace nan with empty string to avoid errors in list comprehension\n",
    "df_file.cntrb_ids.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67970ad6-a7fc-4905-a7f4-34781c290be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce5147-33e3-4abc-9eae-388d0ae4de47",
   "metadata": {
    "tags": []
   },
   "source": [
    "## File preprocessing - group by selected directory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be50a0-f6a7-4b51-a469-68abfdacc524",
   "metadata": {
    "tags": []
   },
   "source": [
    "Split file path by directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8ea67-27f0-4f69-908a-70e7e93cdf75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_file = df_file.join(df_file['file_path'].str.split('/', expand=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47f708-7a81-484b-99e8-ef9e110d0cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c555d8-be32-4957-a77f-69c80b12fdc8",
   "metadata": {},
   "source": [
    "No real known explaination for this besides: if do, everything works, if not it doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95a2bb-3ef0-4f90-9eec-9e0631c4a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason this fixes formating and turns into list, should find better way \n",
    "df_file[\"cntrb_ids\"] = df_file.apply(\n",
    "        lambda row: [x for x in row.cntrb_ids],\n",
    "        axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bbc37-b4c6-495c-861e-b4dab4e29ab9",
   "metadata": {},
   "source": [
    "Get all of the folders/directories in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b5ef4-a816-4282-8585-b6887338fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all of the files, split on the last instance of a / to get directories and top level files \n",
    "directories = df_file[\"file_path\"].str.rsplit(\"/\",n= 1).str[0].tolist()\n",
    "directories = list(set(directories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982d7c2-e846-4ca4-9dff-e9d0460df17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the file names to filter out of the directory set\n",
    "top_level_files = df_file[\"file_name\"][df_file[1].isnull()]\n",
    "directories = [f for f in directories if f not in top_level_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b1ce-b095-4294-9598-c87172826e03",
   "metadata": {},
   "source": [
    "User inputted option, with handling corner case of top level directory. In 8knot this would be a searchable drop down of the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938f9e1-1e06-4ff1-b212-4e5039ef825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory_choosen = \"augur/application\" \n",
    "directory_choosen = \"Top Level\" \n",
    "levels = directory_choosen.count('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83870b16-831e-4bb7-af7c-1bd5dd388984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format for top level directory \n",
    "if directory_choosen == \"Top Level\":\n",
    "    directory_choosen = \"\"\n",
    "    levels = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030723f-6cc8-4049-b393-260e1cd77aea",
   "metadata": {},
   "source": [
    "Get all of the files in the directory or nested in folders in the directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9fc89-ddfa-4a3d-ad4e-126be81708e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynamic_directory = df_file[df_file['file_path'].str.startswith(directory_choosen)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93069239-0b05-4f5a-a99e-b544cab42fc4",
   "metadata": {},
   "source": [
    "Groupby the level above the selected directory for all files nested in folders are together. For each, create a list of all of the contributors who have contributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f70ce-07a2-4d69-82d9-00b74087bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynamic_directory = df_dynamic_directory.groupby(levels+1)[\"cntrb_ids\"].sum().reset_index().rename(columns={levels+1: \"directory_value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ff365-7357-490c-85ff-9fb278343676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynamic_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bd07e-e79a-4b9b-91a2-36a6bb73b59c",
   "metadata": {},
   "source": [
    "Set of cntrb_ids to confirm there are no duplicate cntrb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c0f83-2495-42be-ab97-501d6bd22f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynamic_directory[\"cntrb_ids\"] = df_dynamic_directory.apply(\n",
    "        lambda row: set(row.cntrb_ids),\n",
    "        axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d3d25-3b81-4f93-8266-6f3d6d68f634",
   "metadata": {},
   "source": [
    "### Contributors last activity in repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6712e3f-4901-4757-97d1-b794ab7b99bb",
   "metadata": {},
   "source": [
    "Query for contributions with related contributor information. This query gets the following contributor actions: \n",
    "- Commits \n",
    "- Issues: open, close, comment \n",
    "- Pull Requests: open, close, merge, review, comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb7b4e-6200-4e4b-97b3-12f23843f1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "action_query = salc.sql.text(f\"\"\"\n",
    "                SELECT\n",
    "                        repo_id as id,\n",
    "                        repo_name,\n",
    "                        cntrb_id,\n",
    "                        created_at,\n",
    "                        login,\n",
    "                        action,\n",
    "                        rank\n",
    "                    FROM\n",
    "                        augur_data.explorer_contributor_actions\n",
    "                    WHERE\n",
    "                        repo_id ={repo_id}\n",
    "                \"\"\")\n",
    "df_actions = pd.read_sql(action_query, con=engine)\n",
    "df_actions[\"cntrb_id\"] = df_actions[\"cntrb_id\"].astype(str).str.slice(0, 20)\n",
    "df_actions[\"created_at\"] = pd.to_datetime(df_actions[\"created_at\"], utc=True).dt.date\n",
    "\n",
    "df_actions = df_actions.reset_index()\n",
    "df_actions.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09275435-1a9d-4dc7-b26d-19ab8b5e675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44227a98-1550-4290-b82a-c76d9f40cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions[\"created_at\"] = pd.to_datetime(df_actions[\"created_at\"], utc=True)\n",
    "\n",
    "# sort by created_at date latest to earliest and only keep a contributors most recent activity\n",
    "df_actions = df_actions.sort_values(by=\"created_at\", axis=0, ascending=False)\n",
    "df_actions = df_actions.drop_duplicates(subset='cntrb_id', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f5b3f-6cec-4a24-8677-ec71085690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccessary columns not needed after preprocessing steps\n",
    "df_actions = df_actions.reset_index()\n",
    "df_actions.drop([\"index\",\"id\",\"repo_name\",\"login\",\"action\",\"rank\" ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc8336-29b1-4660-80ce-6b7f47102949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de40ba-cc4b-4914-a5db-5f213dec98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of cntrb_ids and their most recent activity on repo \n",
    "last_contrb = df_actions.set_index('cntrb_id')['created_at'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4befa-cbb9-44db-a3b7-74324f49865c",
   "metadata": {},
   "source": [
    "#### Get list of dates of the most recent activity for each contributor for each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea41bd-8675-4d20-b618-1cb6b36f45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynamic_directory[\"dates\"] = df_dynamic_directory.apply(\n",
    "        lambda row: [last_contrb[x] for x in row.cntrb_ids],\n",
    "        axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8baa65-b1ae-4d3b-a4e7-cf76738af7ef",
   "metadata": {},
   "source": [
    "## Histogram testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d27b5-b0d2-40e7-996e-3e2bbadb404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = df_dynamic_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fbe8c5-c559-49c0-89e1-473119b1268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = plot_data.explode('dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736e6cf-2de9-4de9-b535-c7e85a799fc4",
   "metadata": {},
   "source": [
    "reformat into each row being a directory value and a date of one of the contributors most recent activity. Preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e56813-8f8d-44b6-b5ea-0eafb8ab6a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a9484-7721-487f-9e0e-91658798fe56",
   "metadata": {},
   "source": [
    "Get files that have no contributors and remove from set to prevent errors in grouper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e8904-a053-40a1-9ccb-f09230ea8a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_contribs = plot_data[\"directory_value\"][plot_data.dates.isnull()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2723eb3-8e38-4b4f-90db-97f482076396",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86be3fc-b54f-4826-b0b4-97160b1c4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = plot_data[~plot_data.dates.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bcf32-49ff-417f-b32b-52f905a3a127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a14e0d-7689-4cd2-a704-a860486d984b",
   "metadata": {},
   "source": [
    "Creates df with a column for each month between start and end date. This will be used to confirm that there will be a column for every month even if there is no \"last contribution\" date in it. This greatly improves the heatmap ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2402cb1-e6cd-4a9c-ade5-f48dea013847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates based on action so it represents the length of the project\n",
    "min_date = df_actions.created_at.min()\n",
    "max_date = df_actions.created_at.max()\n",
    "dates = pd.date_range(start=min_date, end=max_date, freq=\"M\", inclusive=\"both\")\n",
    "df_fill = dates.to_frame(index=False, name=\"dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391f13e-e17f-49ef-9815-e147e5a3cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([plot_data, df_fill], axis=0)\n",
    "final[\"directory_value\"] = final[\"directory_value\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ab6da-a2ee-4819-b1b3-f458b9ffa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353a670-13c6-4ebb-87ac-b44332340ca9",
   "metadata": {},
   "source": [
    "Commenting out the groupby on the file_name level dataframe. This is grouping dates by every 2 months (another interval can be choosen) and counting the number of contributors with the last activity at that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3994fb-8b4e-43d1-9a5c-d1ef0d544c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.groupby(pd.Grouper(key = 'dates', freq = '2M'))[\"directory_value\"].value_counts().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc9048-bfd1-4a80-91d9-95d2efa2cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the None row that was used for column formating\n",
    "final.drop('nan', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d847aa-94f7-4dde-94e8-f7444303af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back the files that had no contributors\n",
    "for files in no_contribs: \n",
    "    final.loc[files] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a175e78-7f4b-4a60-86cd-7c401fb2dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e895de4-b6ab-4f51-90f2-832efa6952e0",
   "metadata": {},
   "source": [
    "Plot of the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d382289-1c3f-45ef-b12a-cd1dccb54c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(final, color_continuous_scale=px.colors.sequential.YlOrBr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42784734-f0af-410e-9d50-4318fc6f88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig['layout']['xaxis']['autorange'] = \"reversed\"\n",
    "fig['layout']['yaxis']['tickmode'] = \"linear\"\n",
    "fig['layout']['height'] = 700\n",
    "fig['layout']['coloraxis_colorbar_x'] = -0.15\n",
    "fig['layout']['yaxis']['side'] = 'right'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a8f14-330b-4b35-84eb-1e37d3b1973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb5aef-4f28-4693-8eb1-77b848a5ad16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig.write_image(\"heatmap_directory.png\")\n",
    "Image(filename=\"heatmap_directory.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e21df-7c1f-4c64-a0ce-cd94e20835f7",
   "metadata": {},
   "source": [
    "On the 8knot side I am thinking about 2 drop downs. One to select the repo and one for the directory. The repo one will be populated with the contents of the search bar (need to talk about how to get that) with the one chooose in base case is the first one in the list. The second drop down will be searchable and will be all of the directories/folders that are in the specific repository. Top level will be the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ca5fc-864e-42f8-9487-795b48d66f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10023264-e507-475e-87f4-f22459841b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
