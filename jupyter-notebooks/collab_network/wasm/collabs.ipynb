{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network of collaborators between projects in WASM ecosystem. \n",
    "\n",
    "Contributors in a repo interact with one another via:\n",
    "- co-committing\n",
    "- reviewing each other's PRs\n",
    "- messaging in the same PR thread\n",
    "- messaging in the same issue thread\n",
    "\n",
    "We have previously built and analyzed a graph representation of this and have\n",
    "identified those individuals who are highly connected to other contributors in the same repo.\n",
    "\n",
    "## Repo ecosystem collaboration network\n",
    "\n",
    "Contributors are often participants in more than one repository at once. Likewise, groups of contributors might collaborate with one another in more than one repo at a time. \n",
    "\n",
    "Identifying meta-communities of contributors beyond the scope of an individual repo has implications in studying knowledge retention, project preeminence, and linchpin contributorship, among other things.\n",
    "\n",
    "## Notebook premise\n",
    "\n",
    "In this notebook, we'll build and annotate the collaboration network representation of the following projects:\n",
    "\n",
    "- bytecodealliance/wasmtime\n",
    "- wasmedge/wasmedge\n",
    "- wasmerio/wasmer\n",
    "- wavm/wavm\n",
    "\n",
    "\n",
    "## Notebook Author\n",
    "James Kunstle (jkunstle@redhat.com)\n",
    "\n",
    "### Majority of utility + module code by: \n",
    "Maria Shevchuk (maria410@bu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the required packages. Giving a 'requirements.txt' can be insufficient for \n",
    "# ipynb kernels sometimes, so I'd recommend uncommenting and running the below line if\n",
    "# you don't have all dependencies.\n",
    "# The new version of requirements.txt has all the necessary imports. --- SPG 10/23/2025\n",
    "#%pip install sqlalchemy pandas psycopg2-binary networkx matplotlib scipy nbformat kaleido plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.queries import fetch_data\n",
    "from graph_utils.graph_helper import build_graph, find_threshold, apply_pagerank, draw_network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import colorsys\n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "# Backend dynamic rendering. Will need to be changed for Linux machines.\n",
    "plt.switch_backend('macosx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each repo we're considering, we first build its own collaboration network. A collaboration network \n",
    "is a representation of inter-contributor interactions, modeled with contributors as 'nodes' and \n",
    "interactions as 'edges.' Edge weights are based on the kind of interactions two contributors have\n",
    "had. \n",
    "\n",
    "We merge that collaboration network of one repo with the other collaboration networks created for other repos.\n",
    "\n",
    "Some nodes will have the same identify between two repos- for these nodes, we re-ascribe a color from the\n",
    "average of the node's two origin repos. We also make a note that the node appeared in more than one repo\n",
    "previously, and take the union of all of it's existing edges in both networks.\n",
    "\n",
    "The end product is a network with unique nodes, and each node is connected to all of the other nodes they've \n",
    "collaborated with in the past across all of the studied repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def _to_int_rgb(rgb_triplet):\n",
    "    \"\"\"Coerce (r,g,b) to ints in [0,255], tolerating numpy scalars and 0..1 floats.\"\"\"\n",
    "    r, g, b = [float(x) for x in rgb_triplet]\n",
    "    # If channels look like 0..1, scale to 0..255\n",
    "    if 0.0 <= max(r, g, b) <= 1.0:\n",
    "        r, g, b = r * 255.0, g * 255.0, b * 255.0\n",
    "    r = max(0, min(255, int(round(r))))\n",
    "    g = max(0, min(255, int(round(g))))\n",
    "    b = max(0, min(255, int(round(b))))\n",
    "    return (r, g, b)\n",
    "\n",
    "def _rms_avg_channel(c1, c2):\n",
    "    \"\"\"Root-mean-square average of two channel values, returned as int 0..255.\"\"\"\n",
    "    return max(0, min(255, int(round(math.sqrt(((float(c1)**2 + float(c2)**2) / 2.0))))))\n",
    "\n",
    "def build_ecosystem_graph(repos, start, end):\n",
    "    # color palette across repos in HSV, then to 0..255 RGB ints\n",
    "    valid_colors = [\n",
    "        _to_int_rgb(colorsys.hsv_to_rgb(hue, 1.0, 1.0))\n",
    "        for hue in np.linspace(start=0.05, stop=0.95, num=len(repos))\n",
    "    ]\n",
    "\n",
    "    ecosystem_g = None\n",
    "\n",
    "    for i, (repo, org) in enumerate(repos):\n",
    "        r_data = fetch_data(org, repo)\n",
    "        print(f\"got data for {repo}/{org}\")\n",
    "\n",
    "        r_g = build_graph(\n",
    "            r_data, start, end,\n",
    "            cmt_weight=1.0, ism_weight=0.1, pr_weight=2.0, prm_weight=0.2\n",
    "        )\n",
    "        print(f\"built graph for {repo}/{org}\")\n",
    "\n",
    "        # Set a single repo color for all nodes in this repo graph (normalized to ints)\n",
    "        nx.set_node_attributes(r_g, valid_colors[i], \"color\")\n",
    "        nx.set_node_attributes(r_g, f\"{org}/{repo}\", \"origin\")\n",
    "        print(f\"set attribute for {repo}/{org}\")\n",
    "\n",
    "        if ecosystem_g is None:\n",
    "            ecosystem_g = r_g\n",
    "        else:\n",
    "            combo_g = nx.compose(ecosystem_g, r_g)\n",
    "\n",
    "            # Average colors for nodes present in both graphs (RMS per channel)\n",
    "            shared = r_g.nodes & ecosystem_g.nodes\n",
    "            color_data = {}\n",
    "            for n in shared:\n",
    "                r1, g1, b1 = ecosystem_g.nodes[n]['color']\n",
    "                r2, g2, b2 = r_g.nodes[n]['color']\n",
    "                color_data[n] = (\n",
    "                    _rms_avg_channel(r1, r2),\n",
    "                    _rms_avg_channel(g1, g2),\n",
    "                    _rms_avg_channel(b1, b2),\n",
    "                )\n",
    "            if color_data:\n",
    "                nx.set_node_attributes(combo_g, color_data, 'color')\n",
    "\n",
    "            # Track combined origins for shared nodes\n",
    "            origin_data = {n: f\"{ecosystem_g.nodes[n]['origin']}, {r_g.nodes[n]['origin']}\" for n in shared}\n",
    "            if origin_data:\n",
    "                nx.set_node_attributes(combo_g, origin_data, 'origin')\n",
    "\n",
    "            ecosystem_g = combo_g\n",
    "\n",
    "    # FINAL: build Plotly-friendly color strings, guaranteeing ints\n",
    "    ecosystem_g_colors = []\n",
    "    for n in ecosystem_g.nodes:\n",
    "        r, g, b = _to_int_rgb(ecosystem_g.nodes[n]['color'])\n",
    "        ecosystem_g.nodes[n]['color'] = (r, g, b)  # keep graph clean for later use\n",
    "        ecosystem_g_colors.append(f\"rgb({r},{g},{b})\")\n",
    "\n",
    "    return ecosystem_g, ecosystem_g_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of above logic:\n",
    "\n",
    "The goal of the above function is to combine the collaboration networks of the input repos, creating an 'ecosystem' network, with node-colorings corresponding to the repos that a node was associated with. The overarching pseudo-code is the following:\n",
    "\n",
    "```\n",
    " // ecosystem network object\n",
    "G = None\n",
    "\n",
    "for repo in repolist:\n",
    "    \n",
    "    // network of repo\n",
    "    g = build_network(repo)\n",
    "    \n",
    "    if G is None:\n",
    "        G = g\n",
    "    else:\n",
    "        // merge the existing network with the \n",
    "        // new network\n",
    "        G = combine_networks(G, g)\n",
    "\n",
    "        // overlapping nodes\n",
    "        common_nodes = union(G.nodes, g.nodes)\n",
    "\n",
    "        for n in common_nodes:\n",
    "            // take the running average color of node\n",
    "            n.color = avg(G[n].color, g[n].color)\n",
    "\n",
    "return G\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the visualization of an ecosystem-level collaboration network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrarily starting in January 2017 and ending in September 2023, create the collaboration network of the following four repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) connection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\nconnection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:3301\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3281\u001b[39m \n\u001b[32m   3282\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3299\u001b[39m \n\u001b[32m   3300\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:629\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\nconnection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m start = dt.datetime.strptime(\u001b[33m\"\u001b[39m\u001b[33m1/2017\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m end = dt.datetime.strptime(\u001b[33m\"\u001b[39m\u001b[33m9/2023\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m ecosystem_g, ecosystem_g_colors = \u001b[43mbuild_ecosystem_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mbuild_ecosystem_graph\u001b[39m\u001b[34m(repos, start, end)\u001b[39m\n\u001b[32m     28\u001b[39m ecosystem_g = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (repo, org) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(repos):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     r_data = \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgot data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m     r_g = build_graph(\n\u001b[32m     35\u001b[39m         r_data, start, end,\n\u001b[32m     36\u001b[39m         cmt_weight=\u001b[32m1.0\u001b[39m, ism_weight=\u001b[32m0.1\u001b[39m, pr_weight=\u001b[32m2.0\u001b[39m, prm_weight=\u001b[32m0.2\u001b[39m\n\u001b[32m     37\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/jupyter-notebooks/collab_network/wasm/data_utils/queries.py:46\u001b[39m, in \u001b[36mfetch_data\u001b[39m\u001b[34m(repo_org, repo_name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_data\u001b[39m(repo_org, repo_name):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    Fetch data from the Augur database for different events in a GitHub repository.\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m                                      each pull request message thread.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     cmt_data = \u001b[43mcommit_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_org\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     ism_data = issue_msg_query(repo_org, repo_name)\n\u001b[32m     48\u001b[39m     pr_data = pr_query(repo_org, repo_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/jupyter-notebooks/collab_network/wasm/data_utils/queries.py:116\u001b[39m, in \u001b[36mcommit_query\u001b[39m\u001b[34m(repo_org, repo_name)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03mExecute a SQL query to fetch commit data for a given repository.\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m                  author and committer IDs.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m cmt_query = salc.sql.text(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[33m                SET SCHEMA \u001b[39m\u001b[33m'\u001b[39m\u001b[33maugur_data\u001b[39m\u001b[33m'\u001b[39m\u001b[33m;\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[33m                SELECT\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    113\u001b[39m \u001b[33m                    timestamp DESC\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m cmt_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmt_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m cmt_data = cmt_data.dropna()\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Convert the timestamp column to offset-naive datetime objects\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/pandas/io/sql.py:706\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    703\u001b[39m     dtype_backend = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[32m    708\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_query(\n\u001b[32m    709\u001b[39m             sql,\n\u001b[32m    710\u001b[39m             index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m             dtype=dtype,\n\u001b[32m    717\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/pandas/io/sql.py:908\u001b[39m, in \u001b[36mpandasSQL_builder\u001b[39m\u001b[34m(con, schema, need_transaction)\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy.engine.Connectable)):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m adbc = import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33madbc_driver_manager.dbapi\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc.Connection):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/pandas/io/sql.py:1648\u001b[39m, in \u001b[36mSQLDatabase.__init__\u001b[39m\u001b[34m(self, con, schema, need_transaction)\u001b[39m\n\u001b[32m   1646\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.callback(con.dispose)\n\u001b[32m   1647\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m     con = \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con.in_transaction():\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(con.begin())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:3277\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Connection:\n\u001b[32m   3255\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3256\u001b[39m \n\u001b[32m   3257\u001b[39m \u001b[33;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3274\u001b[39m \n\u001b[32m   3275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:145\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = engine.raw_connection()\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2440\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception_noconnection\u001b[39m\u001b[34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[39m\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2439\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2440\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2442\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    145\u001b[39m         Connection._handle_dbapi_exception_noconnection(\n\u001b[32m    146\u001b[39m             err, dialect, engine\n\u001b[32m    147\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:3301\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m   3280\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3281\u001b[39m \n\u001b[32m   3282\u001b[39m \u001b[33;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3299\u001b[39m \n\u001b[32m   3300\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m    440\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1256\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_checkout\u001b[39m(\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1261\u001b[39m     fairy: Optional[_ConnectionFairy] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1262\u001b[39m ) -> _ConnectionFairy:\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m         fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1267\u001b[39m             threadconns.current = weakref.ref(fairy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    709\u001b[39m     rec = cast(_ConnectionRecord, pool._do_get())\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    714\u001b[39m     dbapi_connection = rec.get_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection()\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inc_overflow():\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m util.safe_reraise():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ConnectionPoolEntry:\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28mself\u001b[39m.__pool = pool\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    902\u001b[39m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[32m    903\u001b[39m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    894\u001b[39m     \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:629\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ai4opensource/cs8630-B/.venv/lib/python3.13/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: (psycopg2.OperationalError) connection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\nconnection to server at \"chaoss.tv\" (67.6.8.193), port 5434 failed: FATAL:  password authentication failed for user \"augur\"\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# repo, org pairs\n",
    "repos = [\n",
    "    (\"wasmtime\", \"bytecodealliance\"),\n",
    "    (\"wasmedge\", \"wasmedge\"),\n",
    "    (\"wasmer\", \"wasmerio\"),\n",
    "    (\"wavm\", \"wavm\")\n",
    "    ]\n",
    "\n",
    "# start of analysis, end of analysis\n",
    "start = dt.datetime.strptime(\"1/2017\", \"%m/%Y\")\n",
    "end = dt.datetime.strptime(\"9/2023\", \"%m/%Y\")\n",
    "\n",
    "ecosystem_g, ecosystem_g_colors = build_ecosystem_graph(repos, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the 'pagerank' algorithm on the network to identify the nodes that are the most connected to one another.\n",
    "\n",
    "Score the nodes in consideration of importance and use that score to render more important nodes as physically larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystem_g_pr_scores, ecosystem_g_normscores = apply_pagerank(ecosystem_g)\n",
    "\n",
    "# for the purpose of the ecosystem drawing, we don't use the threshold value. \n",
    "# the threshold value is only used when we don't override the colors with our own values.\n",
    "ecosystem_g_thresh = find_threshold(np.array(list(ecosystem_g_normscores.values())), [\"percentage\", 10])\n",
    "ecosystem_g_figure = draw_network(ecosystem_g, start, end, ecosystem_g_pr_scores, ecosystem_g_normscores, ecosystem_g_thresh, color_override=ecosystem_g_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystem_g_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an image of the ecosystem for review. Above rendered figure doesn't appear in Github review.\n",
    "ecosystem_g_figure.write_image(\"wasm_ecosystem.png\")\n",
    "Image(filename=\"wasm_ecosystem.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Interpretation:\n",
    "\n",
    "Each 'dot' in the network is a contributor. \n",
    "\n",
    "The size and location of each node is indicative of that contributor's pagerank-centrality in the overall collaboration network.\n",
    "\n",
    "The edges between nodes represent the existence of a relationship- two contributors that participated in the same issue message thread, reviewing each other's PRs, etc.\n",
    "\n",
    "Node color is indicative of the repositories that a given node has participated in. For instance, each individual repo is assigned its own distinct color. If a contributor participates in only one repo, their node color will be identical to the repo's color. If a contributor participates in more than one repo, the color of the contirbutor's node is the average of the colors of the repo they participate in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the network, counting the number of nodes per repo overlap category to see where largest overlaps are.\n",
    "\n",
    "TODO: Colors for the histogram below should be inherited from network above, unsure why they're not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_colors = {}\n",
    "origin_counts = {}\n",
    "\n",
    "for node in ecosystem_g.nodes:\n",
    "\n",
    "    # tri-tuple of RGB\n",
    "    origin = ecosystem_g.nodes[node]['origin']\n",
    "    color = ecosystem_g.nodes[node]['color']\n",
    "\n",
    "    if origin not in origin_colors:\n",
    "        origin_colors[origin] = color\n",
    "    \n",
    "    if origin not in origin_counts:\n",
    "        origin_counts[origin] = 1\n",
    "    else:\n",
    "        origin_counts[origin] += 1\n",
    "\n",
    "# sort by size of overlap\n",
    "origin_counts = sorted([(key, val) for key, val in origin_counts.items()], key=lambda x: x[1])\n",
    "\n",
    "# reorder colors by origin value\n",
    "origin_colors = [origin_colors[origin_val[0]] for origin_val in origin_counts]\n",
    "df_overlap = pd.DataFrame(origin_counts, columns=[\"repos\", \"size_overlap\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw histogram. Represents size of populations in respective collaboration overlap, e.g. at time of writing, 85 contributors had made contributions to wasmtime+wasmer. \n",
    "\n",
    "These counts don't consider contribution quality- a contributor could land in the 'wasmer+wasmtime' pile for a single issue they authored in 2017. This is an area of future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_overlap_frequency = px.bar(df_overlap, x='repos', y='size_overlap', color=origin_colors)\n",
    "px_overlap_frequency.update_layout(showlegend=False)\n",
    "px_overlap_frequency.write_image(\"wasm_histogram.png\")\n",
    "px_overlap_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"wasm_histogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Findings:\n",
    "\n",
    "This notebook is not answering to a particular hypothesis- we are developing this technology as background for future work. However, the above results are good candidates for inspection because they summarize an intuitively sensible finding.\n",
    "\n",
    "The network being considered is a raw collaboration network between people across four communities. The histogram following highlights the populations of contributors conditioned on their historical contribution breadth- WHO has contributed WHERE, naively.\n",
    "\n",
    "We see that, for the majority of contributors, only one project receives attention. There are noticable linchpin contributors in the network that connect WASMTime+WASMEdge, or WASMTime, WASMer, and WAVM, but most contributors participate in only one project.\n",
    "\n",
    "Further study might answer the question of inter-project collaboration quality: for those people who participate in more than one project, are they doing so in the same way? Are those who are influential in one community more likely to be influential in another?\n",
    "\n",
    "## Key take-away:\n",
    "\n",
    "Among the projects studied, there are minor overlaps on contributorship with some noteable linchpins, but even considering collaboration back to 2017, the projects are relatively siloed.\n",
    "\n",
    "## Suggested questions for future work:\n",
    "\n",
    "1. Are the repos studied connected semantically by purpose? If they're in the WASM domain but aren't actually used together in practice (some being Browser WASM while others are serverside) then they'd obviously be fairly disconnected. Could be fertile ground for a project discovery phase- where are the contributors to the known projects also contributing? What does that 2nd round collaboration network reveal about collaboration densities between projects?\n",
    "\n",
    "2. How high-quality are the edges that connect two projects by the proxy of contributor collaboration? If the correspondence is mostly in issue threads, for instance, these lower-impact edges insinuate communication, but don't directly imply technical collaboration or idea sharing.\n",
    "\n",
    "    2.1. If we track this network over time, we could identify a new project that has a high existing-contributor migration signal. This new project, which is inheriting interest from existing contributors, could be very interesting in its ecosystem. We could identify this project by considering anomylous edge creation. \n",
    "\n",
    "\n",
    "3. How strong are project walls? e.g. to what extent do contributors, when clustered empirically, map to a single project versus a cluster that represents multiple projects? If an unsupervised 'n' clustering on the network of 'n' projects yields weak overlap, or significantly better clustering for 'n-m' clusters, this suggests that the collaboration space is in a higher-level embedding (to abuse the term) than repo-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
